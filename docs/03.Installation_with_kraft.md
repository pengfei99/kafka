# 3 Installing and configuring kafka by using KRaft

After kafka 2.8.0, Kafka provide a module KRaft to replace zookeeper for ensuring the consensus between different nodes.

For the basic installation, please check [Installation_with_zk](02.Installation_with_zk.md)

## 3.1 Configure KRaft

With kafka above 2.8.0, when you unzip the binary, in the config folder you should see following contents

```text
connect-console-sink.properties    connect-file-sink.properties    connect-mirror-maker.properties  kraft                server.properties       zookeeper.properties
connect-console-source.properties  connect-file-source.properties  connect-standalone.properties    log4j.properties     tools-log4j.properties
connect-distributed.properties     connect-log4j.properties        consumer.properties              producer.properties  trogdor.conf

```

You could see the old config file such as **server.properties and zookeeper.properties**. There is a new folder called
**kraft**. Open the kraft folder, you should see below configuration files.kraft
```text
broker.properties  controller.properties  README.md  server.properties
```

The **server.properties** file is the main configuration file. Open the **server.properties** file, you should see below
content

```text
# The role of this server. Setting this puts us in KRaft mode
process.roles=broker,controller

# The node id associated with this instance's roles, it must be unique in the cluster
node.id=1

# define the controller which will participate the leader selection.
controller.quorum.voters=1@hadoop01.org:9093

# The address the socket server listens on. It will get the value returned from
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
listeners=PLAINTEXT://:9092,CONTROLLER://:9093
inter.broker.listener.name=PLAINTEXT

# Hostname and port the broker will advertise to producers and consumers. If not set,
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
advertised.listeners=PLAINTEXT://hadoop01.org:9092

# Listener, host name, and port for the controller to advertise to the brokers. If
# this server is a controller, this listener must be configured.
controller.listener.names=CONTROLLER

# A comma separated list of directories under which to store log files (all metadata too with kraft mode)
log.dirs=/home/pliu/Tools/kafka/data/kraft-combined-logs

# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1

```

## 3.2 Initiate the controller log files

```shell
# create a random number
$ ./bin/kafka-storage.sh random-uuid
0Yt6TApMRJ-mzwJCOHEVNg

# formatting the log file
$ ./bin/kafka-storage.sh format -t 0Yt6TApMRJ-mzwJCOHEVNg -c /home/pliu/Tools/kafka/kafka_2.12-3.1.0/config/kraft/server.properties
Formatting /home/pliu/Tools/kafka/data/kraft-combined-logs
```

## 3.3 Start the kafka server and test

```shell
# start the kafka server in daemon mode
$ ./bin/kafka-server-start.sh -daemon config/kraft/server.properties

# create a topic
$ ./bin/kafka-topics.sh --bootstrap-server hadoop01.org:9092 --create --topic test-topic

# list topic
./bin/kafka-topics.sh --bootstrap-server hadoop01.org:9092 --list


# create a console producer
./bin/kafka-console-producer.sh --bootstrap-server hadoop01.org:9092 --topic test-topic

# create a console consumer
./bin/kafka-console-consumer.sh --bootstrap-server hadoop01.org:9092 --topic test-topic

# if you don't see history message, you can add option --from-beginning
./bin/kafka-console-consumer.sh --bootstrap-server hadoop01.org:9092 --topic test-topic --from-beginning
```


## 3.4 Configure kraft mode for multiple server

Suppose you have three sever:
- hadoop01.org
- hadoop02.org
- hadoop03.org

Copy the kafka binary files to /opt/kafka on each server, then edit the **config/kraft/server.properties**
In below example, I only keep the important config. For the other config option, we can use the default value.
We will go deeper on the config in the optimization chapter.

For hadoop01.org server node:

```text
process.roles=broker,controller
node.id=1
controller.quorum.voters=1@hadoop01.org:9093,2@hadoop02.org:9093,3@hadoop03.org:9093
advertised.listeners=PLAINTEXT://hadoop01.org:9092
log.dirs=/home/pliu/Tools/kafka/data/kraft-combined-logs

```

For hadoop02.org server node:

```text
process.roles=broker,controller
node.id=2
controller.quorum.voters=1@hadoop01.org:9093,2@hadoop02.org:9093,3@hadoop03.org:9093
advertised.listeners=PLAINTEXT://hadoop02.org:9092
log.dirs=/home/pliu/Tools/kafka/data/kraft-combined-logs

```

For hadoop03.org server node:

```text
process.roles=broker,controller
node.id=3
controller.quorum.voters=1@hadoop01.org:9093,2@hadoop02.org:9093,3@hadoop03.org:9093
advertised.listeners=PLAINTEXT://hadoop03.org:9092
log.dirs=/home/pliu/Tools/kafka/data/kraft-combined-logs

```

You can notice, the most important config is
- process.roles: indicate the server role, broker and controller. In our case, we only have
             three servers, so all the three servers are broker and controller. In production environment, you don't need
             to have many controller. For example for 100 broker, you can have 11 controller.
- node.id: id of the controller and broker in the cluster, it must be unique for each server
- controller.quorum.voters: This option indicate the url of all controllers that will participate the voting
- advertised.listeners: indicates the url of this server(broker) when facing producer or consumer
- log.dirs: indicates the log file location on the local file system.
